{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct State Codes: ['SA' 'WA' 'VIC' 'QLD' 'NT' 'NSW' 'TAS' 'ACT' 'BC' 'QC' 'ON' 'AB' 'NS'\n",
      " 'SK' 'NU' 'PE' 'MB' 'NL' 'YT' 'NB' 'BB' 'RP' 'BY' 'BW' 'NW' 'NI' 'ST'\n",
      " 'MV' 'SN' 'TH' 'BE' 'HE' 'SL' 'SH' 'HB' 'HH' 'RA' 'IL' 'GY' 'AL' 'AQ'\n",
      " 'CA' 'NP' 'GD' 'FC' 'PA' 'PC' 'LI' 'MP' 'PI' 'HN' 'AU' 'PL' 'LO' 'BN'\n",
      " 'CE' 'LN' 'MQ' 'BO' 'BR' 'CO' 'MY' 'RC' 'VI' 'FE' 'RM' 'AG' 'IM' 'MI'\n",
      " 'PR' 'BG' 'RG' 'PN' 'SV' 'LU' 'CN' 'TN' 'LE' 'PD' 'BI' 'CH' 'GE' 'TO'\n",
      " 'VV' 'CZ' 'AN' 'PG' 'LT' 'BL' 'TV' 'PV' 'MN' 'VA' 'PT' 'SI' 'MS' 'CT'\n",
      " 'BS' 'SS' 'RO' 'CR' 'FI' 'GR' 'IS' 'SO' 'VE' 'OR' 'ME' 'VR' 'CS' 'BZ'\n",
      " 'NO' 'AV' 'TA' 'VC' 'GO' 'MO' 'FR' 'FG' 'TE' 'BA' 'UD' 'AP' 'TP' 'RE'\n",
      " 'PO' 'NAP' 'AT' 'SR' 'RI' 'TS' 'KR' 'MT' 'PZ' 'MC' 'VT' 'AR' 'AO' 'CB'\n",
      " 'LC' 'SP' 'RN' 'FO' 'TR' 'UT' 'NH' 'DR' 'ZH' 'FL' 'OV' 'ZE' 'Falkirk'\n",
      " 'Ceredigion' 'North East Lincolnshire' 'Aberdeenshire' 'York'\n",
      " 'Pembrokeshire' 'Leicester' 'Highland' 'Tendring' 'Horsham' 'Newport'\n",
      " 'Bristol' 'Newark and Sherwood' 'Argyllshire' 'Lincoln' 'Tamworth'\n",
      " 'Fylde' 'Lewes' 'Rhondda Cynon Taf' 'Bromsgrove' 'Ripon' 'Cornwall'\n",
      " 'South Lanarkshire' 'Shropshire' 'Perth and Kinross' 'Crawley'\n",
      " 'Staffordshire' 'Mendip' 'Forest Heath' 'Moray' 'Bracknell Forest'\n",
      " 'Anglesey' 'Bolsover' 'Calderdale' 'Ashford' 'Sussex' 'Darlington'\n",
      " 'East Devon' 'Monmouthshire' 'Gloucester' 'Mid Devon' 'Somerset'\n",
      " 'Hereford' 'Bath and North East Somerset' 'Bassetlaw' 'Christchurch'\n",
      " 'West Berkshire' 'Gwynedd' 'Suffolk' 'Tewkesbury' 'Colchester'\n",
      " 'Llandrindod Wells' 'Harrogate' 'Winchester' 'Angus' 'Derbyshire Dales'\n",
      " 'Dacorum' 'Suffolk Coastal' 'Wiltshire' 'Leeds' 'Kennet' 'Hampshire'\n",
      " 'Norfolk' 'Northumberland' 'Doncaster' 'Purbeck' 'Wyre Forest'\n",
      " 'Redcar & Cleveland' 'West Dorset' 'Ipswich' 'Powys' 'Midlothian' 'Fife'\n",
      " 'North Ayrshire' 'Carmarthenshire' 'Birmingham' 'South Oxfordshire'\n",
      " 'North Yorkshire' 'Cheshire West and Chester' 'Scottish Borders'\n",
      " 'Lichfield' 'Rushcliffe' 'Arun' 'Dumfriesshire' 'Wakefield'\n",
      " 'Denbighshire' 'Plymouth' 'St Edmundsbury' 'Edinburgh' 'Liverpool' 'Kent'\n",
      " 'Warwick' 'Gedling' 'Shetland' 'Flintshire' 'Gravesham'\n",
      " 'Central Bedfordshire' 'North Dorset' 'Lancaster' 'Breckland'\n",
      " 'East Riding of Yorkshire' 'Exeter' 'Vale of White Horse' 'Cherwell'\n",
      " 'South Holland' 'South Lakeland' 'Stroud' 'Orkney Islands' 'West Lindsey'\n",
      " 'Stratford-on-Avon' 'West Oxfordshire' 'Bedford' 'Rother' 'Isle of Man'\n",
      " 'Swindon' 'Charnwood' 'Waverley' 'Wolverhampton' 'Aylesbury Vale'\n",
      " 'Merton' 'Sevenoaks' 'Allerdale' 'Bolton' 'Selby' 'Berkshire' 'Copeland'\n",
      " 'Chelmsford' 'South Kesteven' 'Cheshire East' 'Boston' 'County Durham'\n",
      " 'Mid Suffolk' 'Wandsworth' 'West Dunbartonshire' 'Erewash' 'Babergh'\n",
      " 'South Hams' 'Wigan' 'South Ayrshire' 'Rotherham' 'Isle of Wight'\n",
      " 'Cotswold' 'Worcester' 'Rutland' 'East Northamptonshire' 'Rugby'\n",
      " 'Stirling' 'North Kesteven' 'Comhairle nan Eilean Siar' 'Walsall'\n",
      " 'Knowsley' 'South Somerset' 'North Lincolnshire' 'South Norfolk'\n",
      " 'Aberdeen' 'Welwyn Hatfield' 'Kirkcudbrightshire' 'Carlisle' 'Hillingdon'\n",
      " 'West Norfolk' 'Kirklees' 'New Forest' 'Swansea' 'Craven' 'Camden'\n",
      " 'North Somerset' 'Teignbridge' 'Melton' 'Conwy' 'Enfield' 'Glasgow'\n",
      " 'Braintree' 'Chichester' 'North Hertfordshire' 'East Lothian'\n",
      " 'Renfrewshire' 'Eden' 'Uttlesford' 'Mid Sussex' 'Peterborough' 'Ashfield'\n",
      " 'Redbridge' 'Sheffield' 'Newcastle' 'Harlow' 'East Hampshire'\n",
      " 'Caerphilly' 'North Warwickshire' 'Brentwood' 'Tameside'\n",
      " 'Brighton and Hove' 'Rossendale' 'Swale' 'Sutton' 'Huntingdonshire'\n",
      " 'St Albans' 'Dudley' 'East Hertfordshire' 'Guildford' 'Cambridge'\n",
      " 'Woking' 'Daventry' 'Vale of Glamorgan' 'East Ayrshire' 'Bradford'\n",
      " 'South Buckinghamshire' 'Merthyr Tydfil' 'West Lothian' 'East Lindsey'\n",
      " 'Hambleton' 'Tower Hamlets' 'Test Valley' 'Dartford' 'Sunderland'\n",
      " 'Medway' 'Rochdale' 'Bury' 'Oxford' 'Bridgend' 'South Derbyshire'\n",
      " 'Milton Keynes' 'Southampton' 'Wokingham' 'Nottingham' 'Stevenage'\n",
      " 'Wirral' 'Dundee' 'Amber Valley' 'Harrow' 'East Dorset' 'Maidstone'\n",
      " 'Wigtownshire' 'Gateshead' 'Telford and Wrekin' 'Wellingborough'\n",
      " 'Runnymede' 'Wrexham' 'Cannock Chase' 'Kensington and Chelsea'\n",
      " 'South Gloucestershire' 'Wycombe' 'South Staffordshire' 'Sandwell'\n",
      " 'Bromley' 'Torridge' 'Burnley' 'Sefton' 'Ribble Valley' 'Chiltern'\n",
      " 'Hastings' 'East Staffordshire' 'Barnet' 'Reigate and Banstead'\n",
      " 'Basildon' 'Tandridge' 'Westminster' 'Warrington' 'West Lancashire'\n",
      " 'Preston' 'Canterbury' 'Wealden' 'Havering' 'West Devon' 'Islington'\n",
      " 'Wyre' 'Kinross-Shire' 'Waveney' 'North Lanarkshire' 'Ely'\n",
      " 'Neath Port Talbot' 'Nuneaton & Bedworth' 'Chesterfield' 'Mole Valley'\n",
      " 'South Northamptonshire' 'Broxbourne' 'Cardiff' 'Hackney' 'Redditch'\n",
      " 'Tunbridge Wells' 'Haringey' 'Malvern Hills' 'Broxtowe' 'Spelthorne'\n",
      " 'Coventry' 'Newmarket' 'Lanarkshire' 'East Dunbartonshire'\n",
      " 'Stockton-on-Tees' 'NC' 'MD' 'HI' 'NY' 'TX' 'GA' 'DE' 'WI' 'KS' 'NV' 'MA'\n",
      " 'NJ' 'OH' 'IA' 'KY' 'DC' 'OK' 'ID' 'AZ' 'IN' 'WV' 'NE' 'LA' 'AK' 'ND'\n",
      " 'SC' 'NM' 'SD' 'WY']\n",
      "Distinct State Codes (sorted): ['AB', 'ACT', 'AG', 'AK', 'AL', 'AN', 'AO', 'AP', 'AQ', 'AR', 'AT', 'AU', 'AV', 'AZ', 'Aberdeen', 'Aberdeenshire', 'Allerdale', 'Amber Valley', 'Anglesey', 'Angus', 'Argyllshire', 'Arun', 'Ashfield', 'Ashford', 'Aylesbury Vale', 'BA', 'BB', 'BC', 'BE', 'BG', 'BI', 'BL', 'BN', 'BO', 'BR', 'BS', 'BW', 'BY', 'BZ', 'Babergh', 'Barnet', 'Basildon', 'Bassetlaw', 'Bath and North East Somerset', 'Bedford', 'Berkshire', 'Birmingham', 'Bolsover', 'Bolton', 'Boston', 'Bracknell Forest', 'Bradford', 'Braintree', 'Breckland', 'Brentwood', 'Bridgend', 'Brighton and Hove', 'Bristol', 'Bromley', 'Bromsgrove', 'Broxbourne', 'Broxtowe', 'Burnley', 'Bury', 'CA', 'CB', 'CE', 'CH', 'CN', 'CO', 'CR', 'CS', 'CT', 'CZ', 'Caerphilly', 'Calderdale', 'Cambridge', 'Camden', 'Cannock Chase', 'Canterbury', 'Cardiff', 'Carlisle', 'Carmarthenshire', 'Central Bedfordshire', 'Ceredigion', 'Charnwood', 'Chelmsford', 'Cherwell', 'Cheshire East', 'Cheshire West and Chester', 'Chesterfield', 'Chichester', 'Chiltern', 'Christchurch', 'Colchester', 'Comhairle nan Eilean Siar', 'Conwy', 'Copeland', 'Cornwall', 'Cotswold', 'County Durham', 'Coventry', 'Craven', 'Crawley', 'DC', 'DE', 'DR', 'Dacorum', 'Darlington', 'Dartford', 'Daventry', 'Denbighshire', 'Derbyshire Dales', 'Doncaster', 'Dudley', 'Dumfriesshire', 'Dundee', 'East Ayrshire', 'East Devon', 'East Dorset', 'East Dunbartonshire', 'East Hampshire', 'East Hertfordshire', 'East Lindsey', 'East Lothian', 'East Northamptonshire', 'East Riding of Yorkshire', 'East Staffordshire', 'Eden', 'Edinburgh', 'Ely', 'Enfield', 'Erewash', 'Exeter', 'FC', 'FE', 'FG', 'FI', 'FL', 'FO', 'FR', 'Falkirk', 'Fife', 'Flintshire', 'Forest Heath', 'Fylde', 'GA', 'GD', 'GE', 'GO', 'GR', 'GY', 'Gateshead', 'Gedling', 'Glasgow', 'Gloucester', 'Gravesham', 'Guildford', 'Gwynedd', 'HB', 'HE', 'HH', 'HI', 'HN', 'Hackney', 'Hambleton', 'Hampshire', 'Haringey', 'Harlow', 'Harrogate', 'Harrow', 'Hastings', 'Havering', 'Hereford', 'Highland', 'Hillingdon', 'Horsham', 'Huntingdonshire', 'IA', 'ID', 'IL', 'IM', 'IN', 'IS', 'Ipswich', 'Isle of Man', 'Isle of Wight', 'Islington', 'KR', 'KS', 'KY', 'Kennet', 'Kensington and Chelsea', 'Kent', 'Kinross-Shire', 'Kirkcudbrightshire', 'Kirklees', 'Knowsley', 'LA', 'LC', 'LE', 'LI', 'LN', 'LO', 'LT', 'LU', 'Lanarkshire', 'Lancaster', 'Leeds', 'Leicester', 'Lewes', 'Lichfield', 'Lincoln', 'Liverpool', 'Llandrindod Wells', 'MA', 'MB', 'MC', 'MD', 'ME', 'MI', 'MN', 'MO', 'MP', 'MQ', 'MS', 'MT', 'MV', 'MY', 'Maidstone', 'Malvern Hills', 'Medway', 'Melton', 'Mendip', 'Merthyr Tydfil', 'Merton', 'Mid Devon', 'Mid Suffolk', 'Mid Sussex', 'Midlothian', 'Milton Keynes', 'Mole Valley', 'Monmouthshire', 'Moray', 'NAP', 'NB', 'NC', 'ND', 'NE', 'NH', 'NI', 'NJ', 'NL', 'NM', 'NO', 'NP', 'NS', 'NSW', 'NT', 'NU', 'NV', 'NW', 'NY', 'Neath Port Talbot', 'New Forest', 'Newark and Sherwood', 'Newcastle', 'Newmarket', 'Newport', 'Norfolk', 'North Ayrshire', 'North Dorset', 'North East Lincolnshire', 'North Hertfordshire', 'North Kesteven', 'North Lanarkshire', 'North Lincolnshire', 'North Somerset', 'North Warwickshire', 'North Yorkshire', 'Northumberland', 'Nottingham', 'Nuneaton & Bedworth', 'OH', 'OK', 'ON', 'OR', 'OV', 'Orkney Islands', 'Oxford', 'PA', 'PC', 'PD', 'PE', 'PG', 'PI', 'PL', 'PN', 'PO', 'PR', 'PT', 'PV', 'PZ', 'Pembrokeshire', 'Perth and Kinross', 'Peterborough', 'Plymouth', 'Powys', 'Preston', 'Purbeck', 'QC', 'QLD', 'RA', 'RC', 'RE', 'RG', 'RI', 'RM', 'RN', 'RO', 'RP', 'Redbridge', 'Redcar & Cleveland', 'Redditch', 'Reigate and Banstead', 'Renfrewshire', 'Rhondda Cynon Taf', 'Ribble Valley', 'Ripon', 'Rochdale', 'Rossendale', 'Rother', 'Rotherham', 'Rugby', 'Runnymede', 'Rushcliffe', 'Rutland', 'SA', 'SC', 'SD', 'SH', 'SI', 'SK', 'SL', 'SN', 'SO', 'SP', 'SR', 'SS', 'ST', 'SV', 'Sandwell', 'Scottish Borders', 'Sefton', 'Selby', 'Sevenoaks', 'Sheffield', 'Shetland', 'Shropshire', 'Somerset', 'South Ayrshire', 'South Buckinghamshire', 'South Derbyshire', 'South Gloucestershire', 'South Hams', 'South Holland', 'South Kesteven', 'South Lakeland', 'South Lanarkshire', 'South Norfolk', 'South Northamptonshire', 'South Oxfordshire', 'South Somerset', 'South Staffordshire', 'Southampton', 'Spelthorne', 'St Albans', 'St Edmundsbury', 'Staffordshire', 'Stevenage', 'Stirling', 'Stockton-on-Tees', 'Stratford-on-Avon', 'Stroud', 'Suffolk', 'Suffolk Coastal', 'Sunderland', 'Sussex', 'Sutton', 'Swale', 'Swansea', 'Swindon', 'TA', 'TAS', 'TE', 'TH', 'TN', 'TO', 'TP', 'TR', 'TS', 'TV', 'TX', 'Tameside', 'Tamworth', 'Tandridge', 'Teignbridge', 'Telford and Wrekin', 'Tendring', 'Test Valley', 'Tewkesbury', 'Torridge', 'Tower Hamlets', 'Tunbridge Wells', 'UD', 'UT', 'Uttlesford', 'VA', 'VC', 'VE', 'VI', 'VIC', 'VR', 'VT', 'VV', 'Vale of Glamorgan', 'Vale of White Horse', 'WA', 'WI', 'WV', 'WY', 'Wakefield', 'Walsall', 'Wandsworth', 'Warrington', 'Warwick', 'Waveney', 'Waverley', 'Wealden', 'Wellingborough', 'Welwyn Hatfield', 'West Berkshire', 'West Devon', 'West Dorset', 'West Dunbartonshire', 'West Lancashire', 'West Lindsey', 'West Lothian', 'West Norfolk', 'West Oxfordshire', 'Westminster', 'Wigan', 'Wigtownshire', 'Wiltshire', 'Winchester', 'Wirral', 'Woking', 'Wokingham', 'Wolverhampton', 'Worcester', 'Wrexham', 'Wycombe', 'Wyre', 'Wyre Forest', 'YT', 'York', 'ZE', 'ZH']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "                    #C:\\Users\\ANNIE CHRISTINA G\\Desktop\\data spark\\dataset\\Customers.csv\n",
    "#sales = pd.read_csv('C:/Users/ANNIE CHRISTINA G/Desktop/data spark/dataset/Sales.csv')\n",
    "#customer = pd.read_csv('C:/Users/ANNIE CHRISTINA G/Desktop/data spark/dataset/Customers.csv')\n",
    "\n",
    "# Try different encodings if one doesn't work\n",
    "df = pd.read_csv('C:/Users/ANNIE CHRISTINA G/Desktop/data spark/dataset/updated_customers.csv')\n",
    "\n",
    "# Get the distinct values of the 'StateCode' column\n",
    "distinct_state_codes = df['State Code'].unique()\n",
    "\n",
    "# Print the distinct values\n",
    "print(\"Distinct State Codes:\", distinct_state_codes)\n",
    "# Sort the distinct values\n",
    "sorted_state_codes = sorted(distinct_state_codes)\n",
    "\n",
    "# Print the sorted distinct values\n",
    "print(\"Distinct State Codes (sorted):\", sorted_state_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distinct_state_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerKey    0\n",
      "Gender         0\n",
      "Name           0\n",
      "City           0\n",
      "State Code     0\n",
      "State          0\n",
      "Zip Code       0\n",
      "Country        0\n",
      "Continent      0\n",
      "Birthday       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = '/mnt/data/Customers.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a mapping of state names to their corresponding state codes for common states\n",
    "state_code_mapping = {\n",
    "    'Queensland': 'QLD',\n",
    "    'New South Wales': 'NSW',\n",
    "    'South Australia': 'SA',\n",
    "    'Victoria': 'VIC',\n",
    "    'Western Australia': 'WA',\n",
    "    'Tasmania': 'TAS',\n",
    "    'Northern Territory': 'NT',\n",
    "    'Australian Capital Territory': 'ACT'\n",
    "    # Extend this dictionary as needed for known states\n",
    "}\n",
    "\n",
    "# Function to dynamically generate a state code\n",
    "def generate_state_code(state):\n",
    "    words = state.split()\n",
    "    if len(words) == 1:\n",
    "        return state[:3].upper()\n",
    "    else:\n",
    "        return ''.join([word[:2].upper() for word in words])\n",
    "\n",
    "# Fill missing state codes using the mapping and generate dynamically if not in mapping\n",
    "df['State Code'] = df.apply(\n",
    "    lambda row: state_code_mapping.get(row['State'], generate_state_code(row['State']))\n",
    "    if pd.isnull(row['State Code']) or row['State Code'] == ''\n",
    "    else row['State Code'], axis=1)\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "updated_file_path = '/mnt/data/updated_customers.csv'\n",
    "df.to_csv(updated_file_path, index=False)\n",
    "\n",
    "print(f\"Missing state codes have been filled and the updated file has been saved as '{updated_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct State Codes: ['SA' 'WA' 'VIC' 'QLD' 'NT' 'NSW' 'TAS' 'ACT' 'BC' 'QC' 'ON' 'AB' 'NS'\n",
      " 'SK' 'NU' 'PE' 'MB' 'NL' 'YT' 'NB' 'BB' 'RP' 'BY' 'BW' 'NW' 'NI' 'ST'\n",
      " 'MV' 'SN' 'TH' 'BE' 'HE' 'SL' 'SH' 'HB' 'HH' 'RA' 'IL' 'GY' 'AL' 'AQ'\n",
      " 'CA' 'NP' 'GD' 'FC' 'PA' 'PC' 'LI' 'MP' 'PI' 'HN' 'AU' 'PL' 'LO' 'BN'\n",
      " 'CE' 'LN' 'MQ' 'BO' 'BR' 'CO' 'MY' 'RC' 'VI' 'FE' 'RM' 'AG' 'IM' 'MI'\n",
      " 'PR' 'BG' 'RG' 'PN' 'SV' 'LU' 'CN' 'TN' 'LE' 'PD' 'BI' 'CH' 'GE' 'TO'\n",
      " 'VV' 'CZ' 'AN' 'PG' 'LT' 'BL' 'TV' 'PV' 'MN' 'VA' 'PT' 'SI' 'MS' 'CT'\n",
      " 'BS' 'SS' 'RO' 'CR' 'FI' 'GR' 'IS' 'SO' 'VE' 'OR' 'ME' 'VR' 'CS' 'BZ'\n",
      " 'NO' 'AV' 'TA' 'VC' 'GO' 'MO' 'FR' 'FG' 'TE' 'BA' 'UD' 'AP' 'TP' 'RE'\n",
      " 'PO' 'NAP' 'AT' 'SR' 'RI' 'TS' 'KR' 'MT' 'PZ' 'MC' 'VT' 'AR' 'AO' 'CB'\n",
      " 'LC' 'SP' 'RN' 'FO' 'TR' 'UT' 'NH' 'DR' 'ZH' 'FL' 'OV' 'ZE' 'Falkirk'\n",
      " 'Ceredigion' 'North East Lincolnshire' 'Aberdeenshire' 'York'\n",
      " 'Pembrokeshire' 'Leicester' 'Highland' 'Tendring' 'Horsham' 'Newport'\n",
      " 'Bristol' 'Newark and Sherwood' 'Argyllshire' 'Lincoln' 'Tamworth'\n",
      " 'Fylde' 'Lewes' 'Rhondda Cynon Taf' 'Bromsgrove' 'Ripon' 'Cornwall'\n",
      " 'South Lanarkshire' 'Shropshire' 'Perth and Kinross' 'Crawley'\n",
      " 'Staffordshire' 'Mendip' 'Forest Heath' 'Moray' 'Bracknell Forest'\n",
      " 'Anglesey' 'Bolsover' 'Calderdale' 'Ashford' 'Sussex' 'Darlington'\n",
      " 'East Devon' 'Monmouthshire' 'Gloucester' 'Mid Devon' 'Somerset'\n",
      " 'Hereford' 'Bath and North East Somerset' 'Bassetlaw' 'Christchurch'\n",
      " 'West Berkshire' 'Gwynedd' 'Suffolk' 'Tewkesbury' 'Colchester'\n",
      " 'Llandrindod Wells' 'Harrogate' 'Winchester' 'Angus' 'Derbyshire Dales'\n",
      " 'Dacorum' 'Suffolk Coastal' 'Wiltshire' 'Leeds' 'Kennet' 'Hampshire'\n",
      " 'Norfolk' 'Northumberland' 'Doncaster' 'Purbeck' 'Wyre Forest'\n",
      " 'Redcar & Cleveland' 'West Dorset' 'Ipswich' 'Powys' 'Midlothian' 'Fife'\n",
      " 'North Ayrshire' 'Carmarthenshire' 'Birmingham' 'South Oxfordshire'\n",
      " 'North Yorkshire' 'Cheshire West and Chester' 'Scottish Borders'\n",
      " 'Lichfield' 'Rushcliffe' 'Arun' 'Dumfriesshire' 'Wakefield'\n",
      " 'Denbighshire' 'Plymouth' 'St Edmundsbury' 'Edinburgh' 'Liverpool' 'Kent'\n",
      " 'Warwick' 'Gedling' 'Shetland' 'Flintshire' 'Gravesham'\n",
      " 'Central Bedfordshire' 'North Dorset' 'Lancaster' 'Breckland'\n",
      " 'East Riding of Yorkshire' 'Exeter' 'Vale of White Horse' 'Cherwell'\n",
      " 'South Holland' 'South Lakeland' 'Stroud' 'Orkney Islands' 'West Lindsey'\n",
      " 'Stratford-on-Avon' 'West Oxfordshire' 'Bedford' 'Rother' 'Isle of Man'\n",
      " 'Swindon' 'Charnwood' 'Waverley' 'Wolverhampton' 'Aylesbury Vale'\n",
      " 'Merton' 'Sevenoaks' 'Allerdale' 'Bolton' 'Selby' 'Berkshire' 'Copeland'\n",
      " 'Chelmsford' 'South Kesteven' 'Cheshire East' 'Boston' 'County Durham'\n",
      " 'Mid Suffolk' 'Wandsworth' 'West Dunbartonshire' 'Erewash' 'Babergh'\n",
      " 'South Hams' 'Wigan' 'South Ayrshire' 'Rotherham' 'Isle of Wight'\n",
      " 'Cotswold' 'Worcester' 'Rutland' 'East Northamptonshire' 'Rugby'\n",
      " 'Stirling' 'North Kesteven' 'Comhairle nan Eilean Siar' 'Walsall'\n",
      " 'Knowsley' 'South Somerset' 'North Lincolnshire' 'South Norfolk'\n",
      " 'Aberdeen' 'Welwyn Hatfield' 'Kirkcudbrightshire' 'Carlisle' 'Hillingdon'\n",
      " 'West Norfolk' 'Kirklees' 'New Forest' 'Swansea' 'Craven' 'Camden'\n",
      " 'North Somerset' 'Teignbridge' 'Melton' 'Conwy' 'Enfield' 'Glasgow'\n",
      " 'Braintree' 'Chichester' 'North Hertfordshire' 'East Lothian'\n",
      " 'Renfrewshire' 'Eden' 'Uttlesford' 'Mid Sussex' 'Peterborough' 'Ashfield'\n",
      " 'Redbridge' 'Sheffield' 'Newcastle' 'Harlow' 'East Hampshire'\n",
      " 'Caerphilly' 'North Warwickshire' 'Brentwood' 'Tameside'\n",
      " 'Brighton and Hove' 'Rossendale' 'Swale' 'Sutton' 'Huntingdonshire'\n",
      " 'St Albans' 'Dudley' 'East Hertfordshire' 'Guildford' 'Cambridge'\n",
      " 'Woking' 'Daventry' 'Vale of Glamorgan' 'East Ayrshire' 'Bradford'\n",
      " 'South Buckinghamshire' 'Merthyr Tydfil' 'West Lothian' 'East Lindsey'\n",
      " 'Hambleton' 'Tower Hamlets' 'Test Valley' 'Dartford' 'Sunderland'\n",
      " 'Medway' 'Rochdale' 'Bury' 'Oxford' 'Bridgend' 'South Derbyshire'\n",
      " 'Milton Keynes' 'Southampton' 'Wokingham' 'Nottingham' 'Stevenage'\n",
      " 'Wirral' 'Dundee' 'Amber Valley' 'Harrow' 'East Dorset' 'Maidstone'\n",
      " 'Wigtownshire' 'Gateshead' 'Telford and Wrekin' 'Wellingborough'\n",
      " 'Runnymede' 'Wrexham' 'Cannock Chase' 'Kensington and Chelsea'\n",
      " 'South Gloucestershire' 'Wycombe' 'South Staffordshire' 'Sandwell'\n",
      " 'Bromley' 'Torridge' 'Burnley' 'Sefton' 'Ribble Valley' 'Chiltern'\n",
      " 'Hastings' 'East Staffordshire' 'Barnet' 'Reigate and Banstead'\n",
      " 'Basildon' 'Tandridge' 'Westminster' 'Warrington' 'West Lancashire'\n",
      " 'Preston' 'Canterbury' 'Wealden' 'Havering' 'West Devon' 'Islington'\n",
      " 'Wyre' 'Kinross-Shire' 'Waveney' 'North Lanarkshire' 'Ely'\n",
      " 'Neath Port Talbot' 'Nuneaton & Bedworth' 'Chesterfield' 'Mole Valley'\n",
      " 'South Northamptonshire' 'Broxbourne' 'Cardiff' 'Hackney' 'Redditch'\n",
      " 'Tunbridge Wells' 'Haringey' 'Malvern Hills' 'Broxtowe' 'Spelthorne'\n",
      " 'Coventry' 'Newmarket' 'Lanarkshire' 'East Dunbartonshire'\n",
      " 'Stockton-on-Tees' 'NC' 'MD' 'HI' 'NY' 'TX' 'GA' 'DE' 'WI' 'KS' 'NV' 'MA'\n",
      " 'NJ' 'OH' 'IA' 'KY' 'DC' 'OK' 'ID' 'AZ' 'IN' 'WV' 'NE' 'LA' 'AK' 'ND'\n",
      " 'SC' 'NM' 'SD' 'WY']\n",
      "Distinct State Codes (sorted): ['AB', 'ACT', 'AG', 'AK', 'AL', 'AN', 'AO', 'AP', 'AQ', 'AR', 'AT', 'AU', 'AV', 'AZ', 'Aberdeen', 'Aberdeenshire', 'Allerdale', 'Amber Valley', 'Anglesey', 'Angus', 'Argyllshire', 'Arun', 'Ashfield', 'Ashford', 'Aylesbury Vale', 'BA', 'BB', 'BC', 'BE', 'BG', 'BI', 'BL', 'BN', 'BO', 'BR', 'BS', 'BW', 'BY', 'BZ', 'Babergh', 'Barnet', 'Basildon', 'Bassetlaw', 'Bath and North East Somerset', 'Bedford', 'Berkshire', 'Birmingham', 'Bolsover', 'Bolton', 'Boston', 'Bracknell Forest', 'Bradford', 'Braintree', 'Breckland', 'Brentwood', 'Bridgend', 'Brighton and Hove', 'Bristol', 'Bromley', 'Bromsgrove', 'Broxbourne', 'Broxtowe', 'Burnley', 'Bury', 'CA', 'CB', 'CE', 'CH', 'CN', 'CO', 'CR', 'CS', 'CT', 'CZ', 'Caerphilly', 'Calderdale', 'Cambridge', 'Camden', 'Cannock Chase', 'Canterbury', 'Cardiff', 'Carlisle', 'Carmarthenshire', 'Central Bedfordshire', 'Ceredigion', 'Charnwood', 'Chelmsford', 'Cherwell', 'Cheshire East', 'Cheshire West and Chester', 'Chesterfield', 'Chichester', 'Chiltern', 'Christchurch', 'Colchester', 'Comhairle nan Eilean Siar', 'Conwy', 'Copeland', 'Cornwall', 'Cotswold', 'County Durham', 'Coventry', 'Craven', 'Crawley', 'DC', 'DE', 'DR', 'Dacorum', 'Darlington', 'Dartford', 'Daventry', 'Denbighshire', 'Derbyshire Dales', 'Doncaster', 'Dudley', 'Dumfriesshire', 'Dundee', 'East Ayrshire', 'East Devon', 'East Dorset', 'East Dunbartonshire', 'East Hampshire', 'East Hertfordshire', 'East Lindsey', 'East Lothian', 'East Northamptonshire', 'East Riding of Yorkshire', 'East Staffordshire', 'Eden', 'Edinburgh', 'Ely', 'Enfield', 'Erewash', 'Exeter', 'FC', 'FE', 'FG', 'FI', 'FL', 'FO', 'FR', 'Falkirk', 'Fife', 'Flintshire', 'Forest Heath', 'Fylde', 'GA', 'GD', 'GE', 'GO', 'GR', 'GY', 'Gateshead', 'Gedling', 'Glasgow', 'Gloucester', 'Gravesham', 'Guildford', 'Gwynedd', 'HB', 'HE', 'HH', 'HI', 'HN', 'Hackney', 'Hambleton', 'Hampshire', 'Haringey', 'Harlow', 'Harrogate', 'Harrow', 'Hastings', 'Havering', 'Hereford', 'Highland', 'Hillingdon', 'Horsham', 'Huntingdonshire', 'IA', 'ID', 'IL', 'IM', 'IN', 'IS', 'Ipswich', 'Isle of Man', 'Isle of Wight', 'Islington', 'KR', 'KS', 'KY', 'Kennet', 'Kensington and Chelsea', 'Kent', 'Kinross-Shire', 'Kirkcudbrightshire', 'Kirklees', 'Knowsley', 'LA', 'LC', 'LE', 'LI', 'LN', 'LO', 'LT', 'LU', 'Lanarkshire', 'Lancaster', 'Leeds', 'Leicester', 'Lewes', 'Lichfield', 'Lincoln', 'Liverpool', 'Llandrindod Wells', 'MA', 'MB', 'MC', 'MD', 'ME', 'MI', 'MN', 'MO', 'MP', 'MQ', 'MS', 'MT', 'MV', 'MY', 'Maidstone', 'Malvern Hills', 'Medway', 'Melton', 'Mendip', 'Merthyr Tydfil', 'Merton', 'Mid Devon', 'Mid Suffolk', 'Mid Sussex', 'Midlothian', 'Milton Keynes', 'Mole Valley', 'Monmouthshire', 'Moray', 'NAP', 'NB', 'NC', 'ND', 'NE', 'NH', 'NI', 'NJ', 'NL', 'NM', 'NO', 'NP', 'NS', 'NSW', 'NT', 'NU', 'NV', 'NW', 'NY', 'Neath Port Talbot', 'New Forest', 'Newark and Sherwood', 'Newcastle', 'Newmarket', 'Newport', 'Norfolk', 'North Ayrshire', 'North Dorset', 'North East Lincolnshire', 'North Hertfordshire', 'North Kesteven', 'North Lanarkshire', 'North Lincolnshire', 'North Somerset', 'North Warwickshire', 'North Yorkshire', 'Northumberland', 'Nottingham', 'Nuneaton & Bedworth', 'OH', 'OK', 'ON', 'OR', 'OV', 'Orkney Islands', 'Oxford', 'PA', 'PC', 'PD', 'PE', 'PG', 'PI', 'PL', 'PN', 'PO', 'PR', 'PT', 'PV', 'PZ', 'Pembrokeshire', 'Perth and Kinross', 'Peterborough', 'Plymouth', 'Powys', 'Preston', 'Purbeck', 'QC', 'QLD', 'RA', 'RC', 'RE', 'RG', 'RI', 'RM', 'RN', 'RO', 'RP', 'Redbridge', 'Redcar & Cleveland', 'Redditch', 'Reigate and Banstead', 'Renfrewshire', 'Rhondda Cynon Taf', 'Ribble Valley', 'Ripon', 'Rochdale', 'Rossendale', 'Rother', 'Rotherham', 'Rugby', 'Runnymede', 'Rushcliffe', 'Rutland', 'SA', 'SC', 'SD', 'SH', 'SI', 'SK', 'SL', 'SN', 'SO', 'SP', 'SR', 'SS', 'ST', 'SV', 'Sandwell', 'Scottish Borders', 'Sefton', 'Selby', 'Sevenoaks', 'Sheffield', 'Shetland', 'Shropshire', 'Somerset', 'South Ayrshire', 'South Buckinghamshire', 'South Derbyshire', 'South Gloucestershire', 'South Hams', 'South Holland', 'South Kesteven', 'South Lakeland', 'South Lanarkshire', 'South Norfolk', 'South Northamptonshire', 'South Oxfordshire', 'South Somerset', 'South Staffordshire', 'Southampton', 'Spelthorne', 'St Albans', 'St Edmundsbury', 'Staffordshire', 'Stevenage', 'Stirling', 'Stockton-on-Tees', 'Stratford-on-Avon', 'Stroud', 'Suffolk', 'Suffolk Coastal', 'Sunderland', 'Sussex', 'Sutton', 'Swale', 'Swansea', 'Swindon', 'TA', 'TAS', 'TE', 'TH', 'TN', 'TO', 'TP', 'TR', 'TS', 'TV', 'TX', 'Tameside', 'Tamworth', 'Tandridge', 'Teignbridge', 'Telford and Wrekin', 'Tendring', 'Test Valley', 'Tewkesbury', 'Torridge', 'Tower Hamlets', 'Tunbridge Wells', 'UD', 'UT', 'Uttlesford', 'VA', 'VC', 'VE', 'VI', 'VIC', 'VR', 'VT', 'VV', 'Vale of Glamorgan', 'Vale of White Horse', 'WA', 'WI', 'WV', 'WY', 'Wakefield', 'Walsall', 'Wandsworth', 'Warrington', 'Warwick', 'Waveney', 'Waverley', 'Wealden', 'Wellingborough', 'Welwyn Hatfield', 'West Berkshire', 'West Devon', 'West Dorset', 'West Dunbartonshire', 'West Lancashire', 'West Lindsey', 'West Lothian', 'West Norfolk', 'West Oxfordshire', 'Westminster', 'Wigan', 'Wigtownshire', 'Wiltshire', 'Winchester', 'Wirral', 'Woking', 'Wokingham', 'Wolverhampton', 'Worcester', 'Wrexham', 'Wycombe', 'Wyre', 'Wyre Forest', 'YT', 'York', 'ZE', 'ZH']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "                    #C:\\Users\\ANNIE CHRISTINA G\\Desktop\\data spark\\dataset\\Customers.csv\n",
    "#sales = pd.read_csv('C:/Users/ANNIE CHRISTINA G/Desktop/data spark/dataset/Sales.csv')\n",
    "#customer = pd.read_csv('C:/Users/ANNIE CHRISTINA G/Desktop/data spark/dataset/Customers.csv')\n",
    "\n",
    "# Try different encodings if one doesn't work\n",
    "df = pd.read_csv('C:/Users/ANNIE CHRISTINA G/Desktop/data spark/updated1_customers.csv')\n",
    "                    #C:\\Users\\ANNIE CHRISTINA G\\Desktop\\data spark\\updated1_customers.csv\n",
    "# Get the distinct values of the 'StateCode' column\n",
    "distinct_state_codes = df['State Code'].unique()\n",
    "\n",
    "# Print the distinct values\n",
    "print(\"Distinct State Codes:\", distinct_state_codes)\n",
    "# Sort the distinct values\n",
    "sorted_state_codes = sorted(distinct_state_codes)\n",
    "\n",
    "# Print the sorted distinct values\n",
    "print(\"Distinct State Codes (sorted):\", sorted_state_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerKey    0\n",
      "Gender         0\n",
      "Name           0\n",
      "City           0\n",
      "State Code     0\n",
      "State          0\n",
      "Zip Code       0\n",
      "Country        0\n",
      "Continent      0\n",
      "Birthday       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State codes have been corrected and saved to:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'C:/Users/ANNIE CHRISTINA G/Desktop/data spark/updated1_customers.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Create a function to update state codes based on state names\n",
    "def update_state_code(row):\n",
    "    state_code_map = {\n",
    "        'South Australia': 'SA',\n",
    "        'Western Australia': 'WA',\n",
    "        'Victoria': 'VIC',\n",
    "        'New South Wales': 'NSW',\n",
    "        'Queensland': 'QLD',\n",
    "        'Tasmania': 'TAS',\n",
    "        'Northern Territory': 'NT',\n",
    "        'Australian Capital Territory': 'ACT'\n",
    "    }\n",
    "    \n",
    "    if pd.isna(row['State Code']) or row['State Code'] not in state_code_map.values():\n",
    "        return state_code_map.get(row['State'], row['State Code'])\n",
    "    return row['State Code']\n",
    "\n",
    "# Apply the function to update the 'State Code' column\n",
    "data['State Code'] = data.apply(update_state_code, axis=1)\n",
    "\n",
    "# Ensure all state codes are uppercase (in case there are any lowercase ones)\n",
    "data['State Code'] = data['State Code'].str.upper()\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "\n",
    "data.to_csv('output_file_path.csv', index=False)\n",
    "\n",
    "print(\"State codes have been corrected and saved to:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State codes have been corrected and saved to:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'C:/Users/ANNIE CHRISTINA G/Desktop/data spark/updated1_customers.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Create a function to update state codes based on state names\n",
    "def update_state_code(row):\n",
    "    state_code_map = {\n",
    "        'South Australia': 'SA',\n",
    "        'Western Australia': 'WA',\n",
    "        'Victoria': 'VIC',\n",
    "        'New South Wales': 'NSW',\n",
    "        'Queensland': 'QLD',\n",
    "        'Tasmania': 'TAS',\n",
    "        'Northern Territory': 'NT',\n",
    "        'Australian Capital Territory': 'ACT'\n",
    "    }\n",
    "    \n",
    "    state_name = row['State']\n",
    "    current_code = row['State Code']\n",
    "    \n",
    "    # Update only if current code is invalid or missing\n",
    "    if pd.isna(current_code) or current_code not in state_code_map.values():\n",
    "        return state_code_map.get(state_name, current_code)\n",
    "    return current_code\n",
    "\n",
    "# Apply the function to update the 'State Code' column\n",
    "data['State Code'] = data.apply(update_state_code, axis=1)\n",
    "\n",
    "# Ensure the 'State Code' column matches the expected format (abbreviation)\n",
    "data['State Code'] = data['State Code'].apply(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "#output_file_path = 'path/to/your/updated_customers_corrected.csv'\n",
    "data.to_csv('output_file_path.csv', index=False)\n",
    "\n",
    "print(\"State codes have been corrected and saved to:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'path/to/your/updated1_customers.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Create a function to update state codes based on state names\n",
    "def update_state_code(row):\n",
    "    state_code_map = {\n",
    "        'South Australia': 'SA',\n",
    "        'Western Australia': 'WA',\n",
    "        'Victoria': 'VIC',\n",
    "        'New South Wales': 'NSW',\n",
    "        'Queensland': 'QLD',\n",
    "        'Tasmania': 'TAS',\n",
    "        'Northern Territory': 'NT',\n",
    "        'Australian Capital Territory': 'ACT'\n",
    "    }\n",
    "    \n",
    "    state_name = row['State']\n",
    "    current_code = row['State Code']\n",
    "    \n",
    "    # Update only if current code is invalid or missing\n",
    "    if pd.isna(current_code) or current_code not in state_code_map.values():\n",
    "        return state_code_map.get(state_name, current_code)\n",
    "    return current_code\n",
    "\n",
    "# Function to clean special characters from names\n",
    "def clean_name(name):\n",
    "    # Replace any character that is not a letter, digit, or space with an empty string\n",
    "    cleaned_name = re.sub(r'[^a-zA-Z\\s]', '', name)\n",
    "    # Remove leading and trailing spaces\n",
    "    cleaned_name = cleaned_name.strip()\n",
    "    return cleaned_name\n",
    "\n",
    "# Apply the state code update function\n",
    "data['State Code'] = data.apply(update_state_code, axis=1)\n",
    "\n",
    "# Clean special characters from the 'Name' column\n",
    "data['Name'] = data['Name'].apply(clean_name)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_file_path = 'path/to/your/updated_customers_corrected.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Names have been cleaned and state codes corrected. Saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names and cities have been cleaned and state codes corrected. Saved to:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'C:/Users/ANNIE CHRISTINA G/Desktop/data spark/updated1_customers.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Create a function to update state codes based on state names\n",
    "def update_state_code(row):\n",
    "    state_code_map = {\n",
    "        'South Australia': 'SA',\n",
    "        'Western Australia': 'WA',\n",
    "        'Victoria': 'VIC',\n",
    "        'New South Wales': 'NSW',\n",
    "        'Queensland': 'QLD',\n",
    "        'Tasmania': 'TAS',\n",
    "        'Northern Territory': 'NT',\n",
    "        'Australian Capital Territory': 'ACT'\n",
    "    }\n",
    "    \n",
    "    state_name = row['State']\n",
    "    current_code = row['State Code']\n",
    "    \n",
    "    # Update only if current code is invalid or missing\n",
    "    if pd.isna(current_code) or current_code not in state_code_map.values():\n",
    "        return state_code_map.get(state_name, current_code)\n",
    "    return current_code\n",
    "\n",
    "# Function to clean special characters from names and cities\n",
    "def clean_text(text):\n",
    "    # Replace any character that is not a letter, digit, or space with an empty string\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove leading and trailing spaces\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the state code update function\n",
    "data['State Code'] = data.apply(update_state_code, axis=1)\n",
    "\n",
    "# Clean special characters from the 'Name' column\n",
    "data['Name'] = data['Name'].apply(clean_text)\n",
    "\n",
    "# Clean special characters from the 'City' column\n",
    "data['City'] = data['City'].apply(clean_text)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "#output_file_path = 'path/to/your/updated_customers_corrected.csv'\n",
    "data.to_csv('output_file_path.csv', index=False)\n",
    "\n",
    "print(\"Names and cities have been cleaned and state codes corrected. Saved to:\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
